{
 "metadata": {
  "name": "",
  "signature": "sha256:2e23cfe4bdf9d0f720f7b706a297b1b24a9ec639338d7186fb7a84d07f9c9ec4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "\n",
      "import numpy as np\n",
      "from scipy import sparse\n",
      "from numba import jit"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@jit(nopython=True)\n",
      "def searchsorted(a, v):\n",
      "    lo = -1\n",
      "    hi = len(a)\n",
      "    while(lo < hi-1):\n",
      "        m = (lo + hi) // 2\n",
      "        if v < a[m]:\n",
      "            hi = m\n",
      "        else:\n",
      "            lo = m\n",
      "    return hi"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@jit\n",
      "def mc_sample_path_sp(P, init=0, sample_size=1000):\n",
      "    P = sparse.csr_matrix(P)\n",
      "    n = P.shape[0]\n",
      "    data = P.data\n",
      "    indices = P.indices\n",
      "    indptr = P.indptr\n",
      "\n",
      "    # CDFs, one for each row of P\n",
      "    cdfs1d = np.empty(P.nnz)\n",
      "    for i in range(n):\n",
      "        cdfs1d[indptr[i]:indptr[i+1]] = data[indptr[i]:indptr[i+1]].cumsum()\n",
      "\n",
      "    # Random values, uniformly sampled from [0, 1)\n",
      "    u = np.random.random(size=sample_size)\n",
      "\n",
      "    # === set up array to store output === #\n",
      "    X = np.empty(sample_size, dtype=int)\n",
      "    if isinstance(init, int):\n",
      "        X[0] = init\n",
      "    else:\n",
      "        cdf0 = np.cumsum(init)\n",
      "        X[0] = searchsorted(cdf0, u[0])\n",
      "\n",
      "    # === generate the sample path === #\n",
      "    for t in range(sample_size-1):\n",
      "        k = searchsorted(cdfs1d[indptr[X[t]]:indptr[X[t]+1]], u[t+1])\n",
      "        X[t+1] = indices[indptr[X[t]]+k]\n",
      "\n",
      "    return X"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "P = np.array([[0.4, 0.6], [0.2, 0.8]])\n",
      "init = (0.25, 0.75)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mc_sample_path_sp(P, init=init, sample_size=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "array([0, 1, 1, 1, 1, 1, 1, 1, 1, 0])"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sample_size = 10**4\n",
      "X = mc_sample_path_sp(P, init=init, sample_size=sample_size)\n",
      "print X.sum() / sample_size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.7514\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "P = sparse.csr_matrix([[0.4, 0.6], [0.2, 0.8]])\n",
      "init = (0.25, 0.75)\n",
      "sample_size = 10**5 * 2\n",
      "%timeit mc_sample_path_sp(P, init=init, sample_size=sample_size)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 4.71 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import platform\n",
      "print platform.platform()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Darwin-13.4.0-x86_64-i386-64bit\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "print sys.version"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2.7.8 (default, Jul  2 2014, 10:14:46) \n",
        "[GCC 4.2.1 Compatible Apple LLVM 5.1 (clang-503.0.40)]\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.__version__"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.9.0\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy\n",
      "print scipy.__version__"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.14.0\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numba\n",
      "print numba.__version__"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.18.2\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    }
   ],
   "metadata": {}
  }
 ]
}